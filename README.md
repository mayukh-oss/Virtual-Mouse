# ğŸ–±ï¸ Gesture Controlled Virtual Mouse

A powerful and intuitive gesture-controlled mouse system using **MediaPipe** hand tracking and **OpenCV**. Control your computer's mouse cursor with simple hand gestures captured through your webcam!

![Python Version](https://img.shields.io/badge/python-3.11.9-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

---

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Technology Stack](#technology-stack)
- [System Architecture](#system-architecture)
- [Setup Instructions](#setup-instructions)
- [Usage Guide](#usage-guide)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Screenshots](#screenshots)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

This project implements a **touchless mouse control system** that uses computer vision and machine learning to recognize hand gestures and translate them into mouse actions. Built with MediaPipe's robust hand tracking solution, it provides an accessible, hygienic, and ergonomic alternative to traditional mouse devices.

### Problem It Solves
- âœ… Provides accessible input for users with physical disabilities
- âœ… Reduces repetitive strain injuries from traditional mouse usage
- âœ… Offers hygienic touchless interaction in shared environments
- âœ… Enables natural gesture-based computer interaction
- âœ… Works with standard webcams - no special hardware required

---

## âœ¨ Features

### ğŸ¯ Core Gesture Controls
| Gesture | Action | Description |
|---------|--------|-------------|
| â˜ï¸ Index Finger | **Move Cursor** | Point and move your index finger to control cursor |
| ğŸ¤ Thumb + Index | **Left Click** | Pinch these fingers together for left click |
| ğŸ¤ Thumb + Middle | **Right Click** | Pinch these fingers together for right click |
| âœŠ Hold Pinch + Move | **Drag & Drop** | Keep pinch gesture while moving for drag-drop |
| ğŸ–ï¸ All 5 Fingers | **Scroll** | Extend all fingers and move up/down to scroll |

### ğŸ“Š Advanced Features
- **Real-time FPS Monitoring** - Track performance with live FPS counter
- **Interactive Help Overlay** - Press 'H' for on-screen gesture guide
- **Visual Feedback System** - Color-coded indicators for each gesture
- **Smooth Cursor Movement** - Intelligent smoothing algorithm for natural motion
- **Click Cooldown System** - Prevents accidental multiple clicks
- **Session Statistics** - View average FPS and performance metrics
- **Hand Detection Indicator** - Clear visual feedback when hand is tracked
- **Semi-transparent Info Panel** - Non-intrusive status display

### ğŸ¨ User Experience
- Professional startup sequence with progress indicators
- Real-time gesture mode display (CURSOR/CLICK/SCROLL/DRAG)
- Timestamped action logging in console
- Comprehensive error handling and user guidance
- Graceful shutdown and resource cleanup

---

## ğŸ› ï¸ Technology Stack

### Core Technologies
| Technology | Version | Purpose |
|------------|---------|---------|
| **Python** | 3.11.9 | Primary programming language |
| **OpenCV** | 4.10.0.84 | Video capture and image processing |
| **MediaPipe** | 0.10.14 | Hand tracking and landmark detection |
| **PyAutoGUI** | 0.9.54 | System-level mouse control |
| **NumPy** | 1.26.4 | Mathematical operations and computations |

### Key Libraries
- **cv2 (OpenCV)**: Webcam access, frame processing, visual overlays
- **mediapipe**: 21-point hand landmark detection and tracking
- **pyautogui**: Cross-platform mouse cursor control and clicking
- **numpy**: Distance calculations and coordinate transformations
- **time**: FPS calculation and gesture cooldown timing
- **logging**: Error handling and warning suppression

---

## ğŸ—ï¸ System Architecture

### High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Input Layer                         â”‚
â”‚              (Hand Gestures via Webcam)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Video Capture Layer                         â”‚
â”‚         (OpenCV - Frame Acquisition & Processing)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hand Tracking Layer                             â”‚
â”‚    (MediaPipe - 21 Landmark Detection & Classification)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Gesture Recognition Layer                         â”‚
â”‚  (Distance Calculations, Finger Counting, Mode Detection)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Action Processing Layer                         â”‚
â”‚    (Cursor Smoothing, Click Cooldown, Scroll Handling)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               System Control Layer                           â”‚
â”‚        (PyAutoGUI - Mouse Events & Screen Control)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Structure
```
gesture_mouse/
â”œâ”€â”€ main.py                    # Main application entry point
â”‚   â”œâ”€â”€ get_distance()         # Euclidean distance calculation
â”‚   â”œâ”€â”€ count_extended_fingers() # Finger extension detection
â”‚   â”œâ”€â”€ draw_info_panel()      # UI rendering
â”‚   â”œâ”€â”€ show_help_overlay()    # Help screen rendering
â”‚   â””â”€â”€ main()                 # Core application loop
â”œâ”€â”€ requirements.txt           # Dependency specifications
â”œâ”€â”€ statement.md              # Problem statement document
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ .gitignore               # Git ignore rules
```

---

## ğŸš€ Setup Instructions

### Prerequisites
- **Python 3.11.9** (or compatible 3.7+)
- **Webcam** (built-in or external, minimum 720p recommended)
- **Operating System**: Windows 10/11, macOS 10.15+, or Linux (Ubuntu 20.04+)
- **Minimum 4GB RAM** (8GB recommended)
- **Internet connection** (for initial package installation)

### Step 1: Clone the Repository
```bash
git clone https://github.com/yourusername/gesture-mouse.git
cd gesture-mouse
```

### Step 2: Create Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
# Upgrade pip (recommended)
pip install --upgrade pip

# Install all required packages
pip install -r requirements.txt
```

### Step 4: Verify Installation
```bash
# Check Python version
python --version

# Verify package installation
pip list | grep -E "opencv|mediapipe|pyautogui|numpy"
```

### Step 5: Run the Application
```bash
# Run the main controller module
python gesture_controller.py
```

### Expected Startup Output
```
[CONFIG] Suppressing TensorFlow and MediaPipe warnings...
[CONFIG] âœ“ Warnings suppressed successfully

[CONFIG] Loading video capture settings...
[CONFIG] âœ“ Camera resolution: 1280x720
[CONFIG] âœ“ Target FPS: 60

[GESTURE_UTILS] Loading gesture utility functions...
[GESTURE_UTILS] âœ“ All utility functions loaded successfully

[CONTROLLER] Initializing Gesture Controller module...
[CONTROLLER] âœ“ MediaPipe hands solution loaded
[CONTROLLER] âœ“ Screen resolution detected: 1920x1080

======================================================================
SYSTEM READY - GESTURE CONTROL ACTIVE
======================================================================

âœ¨ AVAILABLE GESTURES:
  ğŸ–±ï¸  Move Cursor      â†’ Point with index finger
  ğŸ‘† Left Click       â†’ Pinch thumb + index finger
  ğŸ–±ï¸  Right Click      â†’ Pinch thumb + middle finger
  âœŠ Drag & Drop      â†’ Hold left click pinch while moving
  ğŸ–ï¸  Scroll          â†’ Extend all 5 fingers and move up/down

âŒ¨ï¸  KEYBOARD CONTROLS:
  Q â†’ Quit program
  H â†’ Show/Hide help overlay
```

---

## ğŸ“– Usage Guide

### Starting the Application
1. Ensure your webcam is connected and not in use by other applications
2. Run `python main.py`
3. Wait for initialization (you'll see progress indicators)
4. Position your hand in front of the camera (center of frame works best)

### Performing Gestures

#### 1. Moving the Cursor
- Extend your **index finger** and point
- Move your hand to control cursor position
- Keep hand in the central 60% of the frame for best accuracy

#### 2. Left Click
- Bring your **thumb and index finger** together (pinch gesture)
- You'll see a **red line** between fingers when close enough
- Release to stop clicking

#### 3. Right Click
- Bring your **thumb and middle finger** together
- You'll see a **blue line** between fingers
- Quick pinch performs single right-click

#### 4. Drag and Drop
- Pinch **thumb and index** to initiate drag mode
- Move your hand while maintaining the pinch
- Release pinch to drop
- "DRAGGING" indicator appears on screen

#### 5. Scrolling
- Extend **all 5 fingers** clearly
- Move hand **up** to scroll up
- Move hand **down** to scroll down
- "SCROLLING" indicator appears on screen

### Keyboard Shortcuts
| Key | Action |
|-----|--------|
| **Q** | Quit the application |
| **H** | Toggle help overlay on/off |

### Tips for Best Performance
1. **Lighting**: Ensure good, even lighting on your hand
2. **Background**: Plain backgrounds improve tracking accuracy
3. **Distance**: Keep hand 1-2 feet from camera
4. **Position**: Center your hand in the frame
5. **Gestures**: Make clear, deliberate gestures
6. **Speed**: Start with slow movements, increase speed as you get comfortable

---

## ğŸ§ª Testing

### Manual Testing Checklist
- [ ] **Module Loading**: Verify all 3 modules load without errors
- [ ] **Configuration**: Check config validation passes
- [ ] **Hand Detection**: Verify "Hand Detected" appears when hand is visible
- [ ] **Cursor Movement**: Check smooth cursor tracking with index finger
- [ ] **Left Click**: Test pinch gesture triggers single click
- [ ] **Right Click**: Verify thumb-middle pinch opens context menus
- [ ] **Drag and Drop**: Test file/folder dragging in file explorer
- [ ] **Scroll**: Verify 5-finger gesture scrolls web pages
- [ ] **FPS Counter**: Confirm FPS displays and stays above 25 FPS
- [ ] **Help Overlay**: Press 'H' to verify help screen displays
- [ ] **Exit**: Press 'Q' to verify clean shutdown

### Module-Level Testing

#### Test config.py
```python
# Test configuration loading
python -c "from config import *; print('Config loaded:', SMOOTHING_FACTOR)"
# Expected output: Config loaded: 7
```

#### Test gesture_utils.py
```python
# Test utility functions
python -c "from gesture_utils import get_distance; print('Distance:', get_distance((0,0), (3,4)))"
# Expected output: Distance: 5.0
```

#### Test gesture_controller.py
```bash
# Full integration test
python gesture_controller.py
# Watch console for 200+ log messages showing system operation
```

### Performance Testing
```bash
# Monitor system resources while running
# Expected values:
# - FPS: 30-60 (depends on hardware)
# - CPU: <50% on modern processors
# - RAM: <500MB
# - Latency: <100ms gesture to action
```

### Test Cases

#### Test Case 1: Basic Cursor Movement
- **Input**: Move index finger left/right/up/down
- **Expected**: Cursor follows smoothly with minimal lag
- **Pass Criteria**: <100ms latency, smooth motion

#### Test Case 2: Click Accuracy
- **Input**: Perform 10 left-click gestures
- **Expected**: Each gesture triggers exactly one click
- **Pass Criteria**: 100% accuracy, no false positives

#### Test Case 3: Gesture Recognition
- **Input**: Perform each gesture 5 times
- **Expected**: Correct gesture mode displayed each time
- **Pass Criteria**: >90% recognition accuracy

### Known Issues & Limitations
1. **Low Light**: Performance degrades in poor lighting
2. **Complex Backgrounds**: Busy backgrounds may affect tracking
3. **Multiple Hands**: System only tracks one hand
4. **Mirror Mode**: Video is flipped for intuitive control
5. **Screen Edges**: Cursor may be less responsive at screen edges

---

## ğŸ“ Project Structure

```
gesture-mouse/
â”‚
â”œâ”€â”€ config.py                  # Configuration module (250+ lines)
â”‚   â”œâ”€â”€ Environment setup      # Warning suppression
â”‚   â”œâ”€â”€ Video capture config   # Camera settings
â”‚   â”œâ”€â”€ MediaPipe settings     # Hand tracking parameters
â”‚   â”œâ”€â”€ Cursor control         # Smoothing and mapping
â”‚   â”œâ”€â”€ Gesture thresholds     # Click/scroll detection
â”‚   â”œâ”€â”€ UI configuration       # Colors, fonts, sizes
â”‚   â”œâ”€â”€ Keyboard shortcuts     # Key bindings
â”‚   â””â”€â”€ Validation logic       # Config verification
â”‚
â”œâ”€â”€ gesture_utils.py           # Utility functions module (450+ lines)
â”‚   â”œâ”€â”€ get_distance()         # Euclidean distance calculation
â”‚   â”œâ”€â”€ count_extended_fingers() # Finger extension detection
â”‚   â”œâ”€â”€ draw_info_panel()      # FPS and mode display
â”‚   â”œâ”€â”€ show_help_overlay()    # Help screen rendering
â”‚   â”œâ”€â”€ draw_hand_detected_indicator() # Detection status
â”‚   â”œâ”€â”€ draw_gesture_indicator()  # Gesture mode display
â”‚   â””â”€â”€ draw_drag_indicator()  # Drag mode indicator
â”‚
â”œâ”€â”€ gesture_controller.py      # Main application module (600+ lines)
â”‚   â”œâ”€â”€ Initialization         # Setup webcam and MediaPipe
â”‚   â”œâ”€â”€ Main processing loop   # Core gesture recognition
â”‚   â”‚   â”œâ”€â”€ Frame capture      # Video input
â”‚   â”‚   â”œâ”€â”€ FPS calculation    # Performance monitoring
â”‚   â”‚   â”œâ”€â”€ Hand detection     # MediaPipe processing
â”‚   â”‚   â”œâ”€â”€ Gesture recognition # Classify hand poses
â”‚   â”‚   â”œâ”€â”€ Mouse control      # PyAutoGUI actions
â”‚   â”‚   â””â”€â”€ UI rendering       # Visual feedback
â”‚   â”œâ”€â”€ Error handling         # Graceful error management
â”‚   â””â”€â”€ Resource cleanup       # Memory and resource release
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies with versions
â”œâ”€â”€ statement.md              # Detailed problem statement
â”œâ”€â”€ README.md                 # This comprehensive documentation
â”œâ”€â”€ ARCHITECTURE.md           # Technical architecture details
â”œâ”€â”€ PROJECT_REPORT.md         # Complete project report
â”œâ”€â”€ .gitignore               # Git ignore patterns
â”‚
â”œâ”€â”€ logs/                     # Application logs (created at runtime)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ screenshots/             # Screenshots for documentation
â”‚   â””â”€â”€ .gitkeep
â”‚
â””â”€â”€ recordings/              # Video recordings (optional)
    â””â”€â”€ .gitkeep
```

### Module Description

#### 1. **config.py** - Configuration Module
- **Purpose**: Centralized configuration management
- **Size**: ~250 lines
- **Key Features**:
  - Suppresses TensorFlow/MediaPipe warnings
  - Configures camera resolution (1280x720)
  - Sets MediaPipe confidence thresholds (0.8)
  - Defines gesture detection parameters
  - Validates configuration values
- **Initialization Output**: 70+ print statements showing setup progress

#### 2. **gesture_utils.py** - Utilities Module
- **Purpose**: Reusable helper functions
- **Size**: ~450 lines
- **Functions**: 7 core utility functions
- **Key Features**:
  - Pure functions (no side effects)
  - Comprehensive docstrings
  - Mathematical formulas explained
  - UI rendering functions
- **Usage**: Imported by gesture_controller.py

#### 3. **gesture_controller.py** - Main Controller
- **Purpose**: Application entry point and main logic
- **Size**: ~600 lines
- **Key Features**:
  - Webcam initialization and configuration
  - MediaPipe hand tracking setup
  - 11-step main processing loop
  - Real-time gesture recognition
  - Mouse control via PyAutoGUI
  - Comprehensive error handling
- **Execution**: `python gesture_controller.py`

### Code Statistics
- **Total Lines**: 1,300+ lines across 3 modules
- **Functions**: 7 utility functions + 1 main function
- **Comments**: 600+ lines (46% documentation)
- **Print Statements**: 200+ for detailed logging
- **Modules**: 3 well-separated concerns
- **Average Cyclomatic Complexity**: 5 (maintainable)

---

## ğŸ“¸ Screenshots

### Main Interface
```
Coming Soon: Screenshot of main application window with hand tracking overlay
```

### Help Overlay
```
Coming Soon: Screenshot of help menu displaying all gestures
```

### Gesture Detection
```
Coming Soon: Screenshots showing each gesture type with visual indicators
```
---

## ğŸ“ License

This project is licensed under the **MIT License**.

```
MIT License

Copyright (c) [year] [fullname]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ‘¨â€ğŸ’» Author

**Your Name**
- ğŸ“ Institution: VIT Bhopal University
- ğŸ“§ Email: mayukh.25bai11291@vitbhopal.ac.in
- ğŸ™ GitHub: [https://github.com/mayukh-oss](https://github.com/mayukh-oss)

---

## ğŸ™ Acknowledgments

- **MediaPipe Team** - For the excellent hand tracking solution
- **OpenCV Community** - For the comprehensive computer vision library
- **PyAutoGUI Developers** - For the cross-platform automation tool
- **Python Community** - For the amazing ecosystem
- **VIT Bhopal** - For academic support and resources

---

## ğŸ“š References

### Technical Documentation
1. [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html) - Official MediaPipe documentation
2. [OpenCV Documentation](https://docs.opencv.org/) - OpenCV API reference
3. [PyAutoGUI Documentation](https://pyautogui.readthedocs.io/) - GUI automation guide
4. [NumPy Documentation](https://numpy.org/doc/) - NumPy user guide

---

## ğŸ“ˆ Project Statistics

- **Total Lines of Code**: 1,300+
- **Modules**: 3 (config, utils, controller)
- **Functions**: 8 major functions
- **Dependencies**: 4 core packages
- **Development Time**: 5+ hours
- **Documentation**: Comprehensive (README, statement, project report)
- **Comment Statements**: 600+ comment lines
- **Print Statements**: 200+ for detailed logging

---

*Last Updated: November 2025*

---

## âœ¨ Features

### ğŸ¯ Gesture Controls
- **ğŸ–±ï¸ Cursor Movement** - Point with your index finger to move the cursor
- **ğŸ‘† Left Click** - Pinch thumb and index finger together
- **ğŸ–±ï¸ Right Click** - Pinch thumb and middle finger together
- **âœŠ Drag & Drop** - Hold left click pinch gesture while moving
- **ğŸ–ï¸ Scroll** - Extend all 5 fingers and move hand up/down

### ğŸ“Š Advanced Features
- **Real-time FPS Monitoring** - Track performance with live FPS counter
- **Interactive Help Overlay** - Press 'H' for gesture guide
- **Visual Feedback** - Color-coded indicators for each gesture
- **Smooth Cursor Movement** - Intelligent smoothing algorithm
- **Click Cooldown** - Prevents accidental multiple clicks
- **Session Statistics** - View average FPS on program exit

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.11.9** (or compatible version)
- **Webcam** (built-in or external)
- **Operating System**: Windows

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/mayukh-oss/Virtual-Mouse.git
   ```

2. **Create a virtual environment** (recommended)
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate

   ```

3. **Install required packages**
   ```bash
   pip install -r requirements.txt
   ```

### Quick Start

Run the main program:
```bash
python gesture_controller.py
```

---

## ğŸ“– Usage Guide

### Basic Controls

| Gesture | Action | Description |
|---------|--------|-------------|
| â˜ï¸ Index Finger | Move Cursor | Point and move your index finger |
| ğŸ¤ Thumb + Index | Left Click | Pinch these fingers together |
| ğŸ¤ Thumb + Middle | Right Click | Pinch these fingers together |
| âœŠ Hold Pinch + Move | Drag & Drop | Keep pinch gesture while moving |
| ğŸ–ï¸ All 5 Fingers | Scroll | Extend all fingers and move up/down |

### Keyboard Controls

| Key | Action |
|-----|--------|
| `Q` | Quit the program |
| `H` | Toggle help overlay |

### Tips for Best Performance

1. **Lighting** - Ensure good lighting for accurate hand detection
2. **Distance** - Keep your hand 1-2 feet from the camera
3. **Position** - Center your hand in the frame for best tracking
4. **Background** - Use a plain background for better detection
5. **Gestures** - Make clear, deliberate gestures for reliable recognition

---

## ğŸ“ Project Structure

```
gesture-mouse/
â”‚
â”œâ”€â”€ gesture_mouse.py      # Main application file
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md            # Project documentation
â”œâ”€â”€ .gitignore          # Git ignore rules
â”œâ”€â”€ LICENSE             # License file
â”‚
â”œâ”€â”€ logs/               # Log files (created at runtime)
â”œâ”€â”€ screenshots/        # Screenshots (optional)
â””â”€â”€ recordings/         # Video recordings (optional)
```

---

## ğŸ“Š System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **CPU** | Dual-core 2.0 GHz | Quad-core 2.5 GHz+ |
| **RAM** | 4 GB | 8 GB+ |
| **Webcam** | 720p @ 30fps | 1080p @ 60fps |
| **Python** | 3.7+ | 3.11.9 |

---

## ğŸ“ License

This project is licensed under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author

**Mayukh Ghosh**
- GitHub: [https://github.com/mayukh-oss](https://github.com/mayukh-oss)
- Email: mayukh.25bai11291@viitbhopal.ac.in

---

## ğŸ™ Acknowledgments

- **MediaPipe** - Google's hand tracking solution
- **OpenCV** - Computer vision library
- **PyAutoGUI** - GUI automation library
- **NumPy** - Scientific computing library

---

## ğŸ“š Documentation

For more detailed documentation, visit:
- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [OpenCV Documentation](https://docs.opencv.org/)
- [PyAutoGUI Documentation](https://pyautogui.readthedocs.io/)

---

## ğŸ”® Future Enhancements

- [ ] Add double-click gesture
- [ ] Implement zoom gesture (pinch with two hands)
- [ ] Add custom gesture recording
- [ ] Support for multiple monitors
- [ ] Add voice commands
- [ ] Create GUI settings panel
- [ ] Add gesture customization
- [ ] Implement gesture macros

---